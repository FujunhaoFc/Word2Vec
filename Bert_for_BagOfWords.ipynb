{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/FujunhaoFc/Word2Vec/blob/main/Bert_for_BagOfWords.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cqIImhF4VG6v",
    "outputId": "09d0d179-eabf-464a-b525-cc54290d9d89"
   },
   "outputs": [],
   "source": [
    "# Install/upgrade required packages (run in first cell)\n",
    "!pip install -q transformers datasets evaluate accelerate\n",
    "\n",
    "# Core imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorWithPadding\n",
    ")\n",
    "from datasets import Dataset, DatasetDict\n",
    "import evaluate\n",
    "\n",
    "# Verify GPU availability\n",
    "print(f\"GPU Available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dXr6TJZ1WcO9"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xvqhAvLEW7-O"
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Up-uHEEUZgur",
    "outputId": "08823c1d-f293-402c-da29-7508c1499783"
   },
   "outputs": [],
   "source": [
    "# Load the competition data\n",
    "train = pd.read_csv('/content/drive/MyDrive/Word2Vec/BagOfWords/labeledTrainData.tsv', delimiter='\\t', quoting=3)\n",
    "test = pd.read_csv('/content/drive/MyDrive/Word2Vec/BagOfWords/testData.tsv', delimiter='\\t', quoting=3)\n",
    "\n",
    "print(f\"Train shape: {train.shape}\")\n",
    "print(f\"Test shape: {test.shape}\")\n",
    "print(f\"\\nSample review (raw):\\n{train['review'][0][:200]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9WTGAE4kauXo",
    "outputId": "84d8fa22-f293-49e8-d556-3b89ce438e01"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download(\"stopwords\")\n",
    "\n",
    "from nltk.corpus import stopwords # Import the stop word list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6cgaxZM_Z3DP"
   },
   "outputs": [],
   "source": [
    "def clean_review(raw_review, remove_stopwords=True):\n",
    "    \"\"\"Enhanced preprocessing that preserves sentiment-critical words\"\"\"\n",
    "    # Remove HTML\n",
    "    review_text = BeautifulSoup(raw_review, \"html.parser\").get_text()\n",
    "\n",
    "    # Handle contractions\n",
    "    review_text = review_text.replace(\"n't\", \" not\")\n",
    "    review_text = review_text.replace(\"'m\", \" am\")\n",
    "    review_text = review_text.replace(\"'s\", \" is\")\n",
    "    review_text = review_text.replace(\"'re\", \" are\")\n",
    "    review_text = review_text.replace(\"'ll\", \" will\")\n",
    "    review_text = review_text.replace(\"'ve\", \" have\")\n",
    "\n",
    "    # Remove non-letters\n",
    "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", review_text)\n",
    "\n",
    "    # Convert to lowercase and split\n",
    "    words = letters_only.lower().split()\n",
    "\n",
    "    if remove_stopwords:\n",
    "        stops = set(stopwords.words(\"english\"))\n",
    "        # Keep negations and important sentiment words\n",
    "        keep_words = {'not', 'no', 'nor', 'never', 'neither', 'nobody',\n",
    "                     'nothing', 'nowhere', 'none', 'barely', 'hardly',\n",
    "                     'scarcely', 'seldom'}\n",
    "        stops = stops - keep_words\n",
    "        words = [w for w in words if w not in stops]\n",
    "\n",
    "    return \" \".join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MnAJibZjaR6p",
    "outputId": "016754e4-26a2-4afc-ba73-37c7b08dfce7"
   },
   "outputs": [],
   "source": [
    "# Apply cleaning\n",
    "train['review'] = train['review'].apply(clean_review)\n",
    "test['review'] = test['review'].apply(clean_review)\n",
    "\n",
    "print(train['review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VjhCNLsla0Jx",
    "outputId": "0cae4253-9fb6-47c1-9c67-6cbc17fe5cb3"
   },
   "outputs": [],
   "source": [
    "# Convert to Hugging Face Dataset format\n",
    "train_dataset = Dataset.from_pandas(train[['review', 'sentiment']])\n",
    "\n",
    "# Rename columns to match Trainer expectations\n",
    "train_dataset = train_dataset.rename_column('review', 'text')\n",
    "train_dataset = train_dataset.rename_column('sentiment', 'labels')\n",
    "\n",
    "# Create 90/10 train/validation split\n",
    "dataset = train_dataset.train_test_split(test_size=0.1, seed=42)\n",
    "print(f\"Train samples: {len(dataset['train'])}\")\n",
    "print(f\"Validation samples: {len(dataset['test'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 362,
     "referenced_widgets": [
      "c746c7e5e9df4155a7cb38baba8b064a",
      "0aa2793766d54a7fa23d5a620176532d",
      "47795a68851b4d71a78bad61100db827",
      "6973af8bd897404a9a7f000e9ef1dfbc",
      "fc828960f22d4f40a72158e1a59c0397",
      "d905146f83ec42ffab4e266833c56474",
      "bbd7c2f7af9045af8a92a623bded1da9",
      "54d5d4bd8fa44c62aa28265aed64c1b4",
      "1d59aa999ee242a1b620f5f5106b513a",
      "aeec061cbedc4696b19c6b36473bfeae",
      "d349863d90db45739ed5a282b58d3aff",
      "89eb3cf8cdde4aa4b42b0adf2dc41cf6",
      "4703a7926c0546ee8ccab37867fa1f1c",
      "40c2f8f71e1846bfb31134ffd84d3a81",
      "c64bb84ee87f4e04980d7f08d4a70b42",
      "d0a23bb0c1964675bd61d38ec6cc76d8",
      "c342486e5f894729ad65bdca4a6997fd",
      "e5af8eb079c04fcbb32aa8165f369d6f",
      "fb5515a44721417287c1d572f7a400bb",
      "696b39559e854c17b7dd82da5271d1ca",
      "cac202ba231048d0b486d081110f2096",
      "d91231955c7347bea4c6f8bedc9b23bd",
      "3507a72b8b2347f7a8a8b4f55c610abd",
      "f485d4e6ab9d40ebbc5c03ded606cf89",
      "a1b30a67a4f14203a6e586a8db1029fa",
      "f155056268bf4894978513202ea45ab3",
      "0792e5e799f246b4ad3bf04eac38e3fc",
      "3edee596b39346ae94050f3b34b2a4af",
      "1e8af9d9817a4002975e686b491e6f2f",
      "bc3021e3a4a042659463068a2b4d4a79",
      "f9b5d127073e4be2bb96f1b06bb9f6b2",
      "d1bdac8241a24cea8ebf6e5d4123f81b",
      "b635e00846e1435882183d8117834601",
      "9c41f71036a84203967127e7eb6bf0a9",
      "de2c85d5fe7846e199ce38a92f9cf8d6",
      "c7cbf3cb61d74df2be1ef32b981a8072",
      "66bf1865b0d64526a6eb665892a11fa5",
      "7de8cfea8e2d4718aa4f8c87b5524c8e",
      "b51347f0c10d43c4acccefa5cb186002",
      "8b2805e4cd5f4080aeff5e88cbe750b7",
      "17a1a0002767459fad5f8a430f605cc4",
      "fedc084abd034034a7c1438b70804170",
      "7f67bdd5b29c433e9ab2a32f6abd7d93",
      "9db44ce7c7144c8c9de4c4ba4513019a",
      "6ba69c4f53e84112943bea7e01eb4529",
      "02bee2cc3e534a41989e25c5e4472123",
      "70539b92a5584197aa5a6f7516024154",
      "9b16b11116db4de9a66a01992c530200",
      "bb9ea3b10a054f1d87d65739f4a6f1c0",
      "523a1c4dd5e14645a6ee41cd16ebe669",
      "61035400634647a68b35db17b405a35e",
      "78a5944fd70e41d89c393070eba98fac",
      "41177e281e0c4f63ad4129020b1631dc",
      "436780a2c4394983808da914d82c9791",
      "30ffbbfd205d44489cd2f1c63539a847",
      "a0942e2c7be640d3a6982cee4f03b739",
      "ad0bda57afb9457b8c90ccbadf11d775",
      "4289b7dd7f4047d4817a0e54e75ccb33",
      "15ebd31c19f84404a26e9ba5988a3876",
      "3c997a21bc0b4798b348170bd4ee4aa8",
      "74ef4257d62940c8b481fd68ee7a4d0e",
      "b0a38bf48ed3424687f520a520668b3d",
      "fb8327e820ff408493344c1a3088c5eb",
      "186384a500354486b991570469d76286",
      "18b1a703b16d4f84b6e40358b6bbfbd8",
      "8456e16067b4400cbb85eb7f7726014e"
     ]
    },
    "id": "H_mDcgE-bIBd",
    "outputId": "9a93e791-2cb2-494c-d127-5398f2dbf712"
   },
   "outputs": [],
   "source": [
    "# Initialize tokenizer - must match your chosen model\n",
    "model_name = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Define tokenization function with memory-optimized settings\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(\n",
    "        examples[\"text\"],\n",
    "        padding=False,        # Dynamic padding in data collator (more efficient)\n",
    "        truncation=True,      # Truncate sequences longer than max_length\n",
    "        max_length=256,       # Reduced from 512 for better memory usage\n",
    "        return_tensors=None   # Return lists, not tensors (for datasets.map)\n",
    "    )\n",
    "\n",
    "# Apply tokenization with batching for speed\n",
    "tokenized_dataset = dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# Inspect tokenized output\n",
    "print(\"Tokenized sample:\")\n",
    "print(f\"Input IDs length: {len(tokenized_dataset['train'][0]['input_ids'])}\")\n",
    "print(f\"Attention mask length: {len(tokenized_dataset['train'][0]['attention_mask'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7KgL-56LmHiL"
   },
   "outputs": [],
   "source": [
    "# Create data collator for efficient dynamic padding\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 134,
     "referenced_widgets": [
      "514454ae65d048cd87654150ea803420",
      "93ab4b5b9f1e43f19c512bc5c01af0b0",
      "f2e18e62e3024208b5ea17c2d20c50ff",
      "d949f3b9ce114dd0a2e788672c175321",
      "3b79f9b488994c158fc5e7f7c1da2edf",
      "4c9f4bd084a34573a6055c4ef547b37f",
      "c2a41a84739946ef9a323711371003d6",
      "90197b5d3cfe4cb4bff1fb098cfd3c6c",
      "6f4a9a4f562442b58ea09e281a54b43d",
      "c671074a510c424d984aaba393864fd8",
      "f2a38fd01dff4ba3ad0ca55048db5921"
     ]
    },
    "id": "ePjTGhdEmOtW",
    "outputId": "23cb2099-86d1-44c2-9b4c-e5190700264e"
   },
   "outputs": [],
   "source": [
    "# Load model with binary classification head\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=2,                                  # Binary classification\n",
    "    id2label={0: \"NEGATIVE\", 1: \"POSITIVE\"},      # Label mapping for interpretability\n",
    "    label2id={\"NEGATIVE\": 0, \"POSITIVE\": 1}       # Reverse mapping\n",
    ")\n",
    "\n",
    "# Check model size\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Total parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "print(f\"Model size: ~{total_params * 4 / 1024**2:.1f} MB (fp32)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0Uqb3u_pmOyQ"
   },
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    # Output and checkpointing\n",
    "    output_dir=\"/content/drive/MyDrive/Word2Vec/imdb_bert_results\",\n",
    "    save_strategy=\"steps\",              # More frequent saves due to disconnect risk\n",
    "    save_steps=500,                     # Save every 500 steps (every ~15 min)\n",
    "    save_total_limit=2,                 # Keep last 2 checkpoints\n",
    "    load_best_model_at_end=True,           # Critical: load best checkpoint after training\n",
    "\n",
    "    # Training parameters\n",
    "    num_train_epochs=3,                    # 2-3 epochs typical for BERT fine-tuning\n",
    "    per_device_train_batch_size=16,        # Balanced for P100 with fp16\n",
    "    per_device_eval_batch_size=32,         # Evaluation can use larger batches\n",
    "\n",
    "    # Optimizer and learning rate\n",
    "    learning_rate=2e-5,                    # Standard BERT fine-tuning LR (2e-5 to 5e-5)\n",
    "    weight_decay=0.01,                     # L2 regularization\n",
    "    warmup_steps=500,                      # Gradual LR warmup for stability\n",
    "\n",
    "    # Evaluation strategy\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=500,                     # Evaluate every 500 steps\n",
    "    metric_for_best_model=\"f1\",           # Use F1 for model selection\n",
    "    greater_is_better=True,\n",
    "\n",
    "    # Memory optimization (critical for Kaggle)\n",
    "    fp16=True,                            # Mixed precision: 2x speed, 50% memory\n",
    "    gradient_accumulation_steps=2,         # Effective batch size = 16 * 2 = 32\n",
    "    gradient_checkpointing=False,          # Disabled for speed (enable if OOM)\n",
    "\n",
    "    # Performance optimization\n",
    "    dataloader_num_workers=2,              # Parallel data loading\n",
    "    dataloader_pin_memory=True,            # Faster CPU->GPU transfer\n",
    "\n",
    "    # Logging\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=100,\n",
    "    logging_strategy=\"steps\",\n",
    "    report_to=\"none\",                      # Disable wandb/tensorboard on Kaggle\n",
    "\n",
    "    # Resume from checkpoint on disconnect\n",
    "    resume_from_checkpoint=True,\n",
    "\n",
    "    # Disable push to hub (not needed for competition)\n",
    "    push_to_hub=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 368,
     "referenced_widgets": [
      "841a536923a245778e94786704a9ad95",
      "69d0950b533d4fd3addfca1177ee453d",
      "78340ed9839644459023933c34ef0eff",
      "02c5eb687d334191947710c9e379d432",
      "1412b9da106b4bffb4bf36f9e5af81e2",
      "e881a5d4ee2c4dbc94825c1deb54ea8d",
      "b9981a6c912d4fcc916ba2dbcd137369",
      "f854d2eb07f946e3b4ea4986c9aa6b88",
      "2b00420d227747ac8261704e6b0dd0b2",
      "ee7d3f223731412e911805bfb2482500",
      "57220112afa8495498895d2f7dd1d139",
      "468e578bb2a3438cbf24f9a1cfb9ce3a",
      "b04c766cbfb44d2095ae7e1a2f119f26",
      "6c840fb69d1c40be9837d3bbd5c45fbd",
      "e734a8db13fd4534b02bcded601ecf67",
      "a88141b738164925a27f10d208bcd63d",
      "7a33ca6431b94407ba9afd0c12f85d2f",
      "d963611111b74736b232f2a7933ae742",
      "6167d8a810294f69949048f71ba128f1",
      "3e1f491cacc54f03b5f42737deca629d",
      "edf303f3c1d0444988d02d95d3d2e051",
      "12b93608d41046aba2d4ea83752184b7"
     ]
    },
    "id": "ODTC166ytVdP",
    "outputId": "cbf4ddd7-c44a-4db7-cbe6-f00386294f64"
   },
   "outputs": [],
   "source": [
    "# Define evaluation metrics\n",
    "accuracy_metric = evaluate.load(\"accuracy\")\n",
    "f1_metric = evaluate.load(\"f1\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    \"\"\"\n",
    "    Compute accuracy and F1 score for evaluation.\n",
    "    Called automatically by Trainer during evaluation.\n",
    "    \"\"\"\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "\n",
    "    accuracy = accuracy_metric.compute(predictions=predictions, references=labels)[\"accuracy\"]\n",
    "    f1 = f1_metric.compute(predictions=predictions, references=labels, average=\"binary\")[\"f1\"]\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"f1\": f1\n",
    "    }\n",
    "\n",
    "# Initialize Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    processing_class=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# Train the model (this is where the magic happens)\n",
    "print(\"Starting training...\")\n",
    "trainer.train()\n",
    "\n",
    "# Evaluate on validation set\n",
    "print(\"\\nEvaluating on validation set...\")\n",
    "results = trainer.evaluate()\n",
    "print(f\"Validation Accuracy: {results['eval_accuracy']:.4f}\")\n",
    "print(f\"Validation F1: {results['eval_f1']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "id": "hp7K9jGvv-29",
    "outputId": "6d76525b-76aa-4a9f-f296-9b160d3d7de6"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def detailed_evaluation(trainer, dataset, dataset_name=\"Validation\"):\n",
    "    \"\"\"\n",
    "    Generate comprehensive evaluation with confusion matrix and per-class metrics.\n",
    "    \"\"\"\n",
    "    # Get predictions\n",
    "    predictions = trainer.predict(dataset)\n",
    "    pred_labels = predictions.predictions.argmax(axis=-1)\n",
    "    true_labels = predictions.label_ids\n",
    "\n",
    "    # Classification report\n",
    "    print(f\"\\n{dataset_name} Set Classification Report:\")\n",
    "    print(classification_report(\n",
    "        true_labels,\n",
    "        pred_labels,\n",
    "        target_names=[\"Negative\", \"Positive\"],\n",
    "        digits=4\n",
    "    ))\n",
    "\n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(true_labels, pred_labels)\n",
    "    print(f\"\\nConfusion Matrix:\")\n",
    "    print(f\"TN: {cm[0,0]}, FP: {cm[0,1]}\")\n",
    "    print(f\"FN: {cm[1,0]}, TP: {cm[1,1]}\")\n",
    "\n",
    "    # Calculate additional metrics\n",
    "    accuracy = (cm[0,0] + cm[1,1]) / cm.sum()\n",
    "    precision = cm[1,1] / (cm[1,1] + cm[0,1])\n",
    "    recall = cm[1,1] / (cm[1,1] + cm[1,0])\n",
    "    f1 = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "    print(f\"\\nSummary Metrics:\")\n",
    "    print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall:    {recall:.4f}\")\n",
    "    print(f\"F1 Score:  {f1:.4f}\")\n",
    "\n",
    "    return pred_labels, true_labels, cm\n",
    "\n",
    "# Run detailed evaluation\n",
    "pred_labels, true_labels, cm = detailed_evaluation(\n",
    "    trainer,\n",
    "    tokenized_dataset[\"test\"],\n",
    "    \"Validation\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 117,
     "referenced_widgets": [
      "2c9cd0e4e8e240078d802fd7feaf32a8",
      "824a3af355a8404495ec534eaea0813c",
      "f7204562aec143dca04dc6243247fbf9",
      "42ff6dbd43f34f86b584fd5286746319",
      "fb25311986ed45ba96b107c9e3968317",
      "a9ba784dbf42487cabe5c26ec0d3b7ff",
      "b493cbe7197e4dd7a8c18f079f0ebb54",
      "b71589f7c75648db8bebd8b7188b3772",
      "92f12f911eb54958b42cb5035c2f7c8e",
      "1704d1cf22294eceb5b64bb46d37a599",
      "4add262708424fd493e60969e0f364f6"
     ]
    },
    "id": "aIByhl2mzjVR",
    "outputId": "8b1a6311-cd42-407b-d159-7dc9c98e4371"
   },
   "outputs": [],
   "source": [
    "# Convert to Dataset and tokenize\n",
    "test_dataset = Dataset.from_pandas(test[['review']])\n",
    "test_dataset = test_dataset.rename_column('review', 'text')\n",
    "test_tokenized = test_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# Generate predictions using Trainer\n",
    "print(\"Generating predictions on test set...\")\n",
    "predictions = trainer.predict(test_tokenized)\n",
    "\n",
    "# Extract predicted labels (argmax of logits)\n",
    "pred_labels = predictions.predictions.argmax(axis=-1)\n",
    "\n",
    "# Optional: Get prediction probabilities\n",
    "import torch.nn.functional as F\n",
    "probs = F.softmax(torch.tensor(predictions.predictions), dim=-1)\n",
    "confidence_scores = probs.max(dim=-1).values.numpy()\n",
    "\n",
    "print(f\"Predictions generated: {len(pred_labels)}\")\n",
    "print(f\"Class distribution: {np.bincount(pred_labels)}\")\n",
    "print(f\"Average confidence: {confidence_scores.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BqlgsgiG0MIb",
    "outputId": "558c8c2f-99d5-42c9-9477-c6a785b7ea46"
   },
   "outputs": [],
   "source": [
    "def predict_sentiment(text, trainer, tokenizer, threshold=0.5):\n",
    "    \"\"\"\n",
    "    Predict sentiment for a single text with confidence score.\n",
    "    \"\"\"\n",
    "    # Clean and tokenize\n",
    "    cleaned_text = clean_review(text)\n",
    "    inputs = tokenizer(\n",
    "        cleaned_text,\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=256,\n",
    "        return_tensors=\"pt\"\n",
    "    ).to(trainer.model.device)\n",
    "\n",
    "    # Get prediction\n",
    "    with torch.no_grad():\n",
    "        outputs = trainer.model(**inputs)\n",
    "        probs = F.softmax(outputs.logits, dim=-1)\n",
    "        predicted_class = probs.argmax().item()\n",
    "        confidence = probs.max().item()\n",
    "\n",
    "    return {\n",
    "        \"sentiment\": \"POSITIVE\" if predicted_class == 1 else \"NEGATIVE\",\n",
    "        \"confidence\": confidence,\n",
    "        \"label\": predicted_class\n",
    "    }\n",
    "\n",
    "# Test on sample texts\n",
    "sample_texts = [\n",
    "    \"This movie was absolutely fantastic! Highly recommend it.\",\n",
    "    \"Terrible film. Waste of time and money.\",\n",
    "    \"It was okay, nothing special but not terrible either.\"\n",
    "]\n",
    "\n",
    "for text in sample_texts:\n",
    "    result = predict_sentiment(text, trainer, tokenizer)\n",
    "    print(f\"Text: {text[:60]}...\")\n",
    "    print(f\"Prediction: {result['sentiment']} (confidence: {result['confidence']:.2%})\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QCZke9Rr1Ofm",
    "outputId": "07fcd55f-d953-42f7-bf7e-623547907493"
   },
   "outputs": [],
   "source": [
    "# Create submission DataFrame\n",
    "submission = pd.DataFrame({\n",
    "    'id': test['id'],\n",
    "    'sentiment': pred_labels\n",
    "})\n",
    "\n",
    "# Verify submission format\n",
    "print(\"Submission Preview:\")\n",
    "print(submission.head(10))\n",
    "print(f\"\\nSubmission shape: {submission.shape}\")\n",
    "print(f\"Sentiment distribution:\\n{submission['sentiment'].value_counts()}\")\n",
    "\n",
    "# Sanity checks\n",
    "assert submission.shape[0] == 25000, \"Wrong number of predictions!\"\n",
    "assert set(submission['sentiment'].unique()) == {0, 1}, \"Invalid labels!\"\n",
    "assert submission['id'].nunique() == 25000, \"Duplicate IDs!\"\n",
    "\n",
    "# Save submission file\n",
    "import csv\n",
    "submission.to_csv(\n",
    "    '/content/drive/MyDrive/Word2Vec/submission.csv',\n",
    "    index=False,\n",
    "    quoting=csv.QUOTE_NONE,      # Don't quote any fields\n",
    "    escapechar='\\\\'               # Escape character for special cases\n",
    ")\n",
    "print(\"\\nSubmission file saved to: /content/drive/MyDrive/Word2Vec/submission.csv\")\n",
    "\n",
    "# Display first few lines to verify format\n",
    "with open('/content/drive/MyDrive/Word2Vec/submission.csv', 'r') as f:\n",
    "    print(\"\\nSubmission file contents:\")\n",
    "    for i, line in enumerate(f):\n",
    "        print(line.strip())\n",
    "        if i >= 5:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wb80HEr31nVc"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Next Part of this task is using other model like roBerta, deBerta, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNLPmakihO794cM25NMZyp/",
   "gpuType": "T4",
   "include_colab_link": true,
   "mount_file_id": "15Rn-dawhAvdKwoyjmw1PLxlq6BwaUqai",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
